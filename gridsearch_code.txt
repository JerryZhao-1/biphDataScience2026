============================================================
Cell 0 [code]
============================================================
import pandas as pd
import numpy as np

# 1. 加载数据
# 请根据你的实际文件路径修改这里，例如 'Warton/Data/whl_2025.csv'
file_path = 'd:/A/Warton/Data/whl_2025.csv'
df = pd.read_csv(file_path)

# 2. 聚合数据 (从 Shift Level -> Game Level)
agg_rules = {
    'home_goals': 'sum',
    'away_goals': 'sum',
    'home_xg': 'sum',
    'away_xg': 'sum',
    'home_shots': 'sum',
    'away_shots': 'sum',
    'went_ot': 'max',
    'home_team': 'first',
    'away_team': 'first'
}

# 生成 df_games
df_games = df.groupby('game_id').agg(agg_rules).reset_index()

# 3. 计算积分 (后续可能用到)
# 逻辑：常规胜=3, 加时胜=2, 加时负=1, 常规负=0
home_win = df_games['home_goals'] > df_games['away_goals']
away_win = df_games['away_goals'] > df_games['home_goals']
is_ot = df_games['went_ot'] == 1

df_games['home_points'] = 0
df_games.loc[home_win & ~is_ot, 'home_points'] = 3
df_games.loc[home_win & is_ot, 'home_points'] = 2
df_games.loc[away_win & is_ot, 'home_points'] = 1

df_games['away_points'] = 0
df_games.loc[away_win & ~is_ot, 'away_points'] = 3
df_games.loc[away_win & is_ot, 'away_points'] = 2
df_games.loc[home_win & is_ot, 'away_points'] = 1

print(f"✅ 成功生成 df_games，共 {len(df_games)} 场比赛。")
print("现在你可以继续运行 Ridge 回归的代码了。")

============================================================
Cell 1 [code]
============================================================
import pandas as pd
import numpy as np
from sklearn.linear_model import Ridge
from sklearn.model_selection import GridSearchCV
import matplotlib.pyplot as plt

# 1. 确保使用比赛级数据 (Game Level Data)
# 注意：我们只使用训练集 (dataset_type == 'train')
# 假设你之前的 df_games 已经生成好了
df_train_ridge = df_games.copy()

# 2. 构建特征矩阵 (X) 和 标签 (y)
print("正在构建回归矩阵...")

# 获取所有球队列表
teams = pd.concat([df_train_ridge['home_team'], df_train_ridge['away_team']]).unique()
teams.sort()

# 创建空的 DataFrame (每一行是一场比赛，每一列是一支球队)
# 这可能会比较慢，如果有几千场比赛，建议使用 scipy.sparse，但对于 WHL 数据集，Pandas 足够了
X = pd.DataFrame(0, index=df_train_ridge.index, columns=teams)

# 填充 1 (主队) 和 -1 (客队)
for idx, row in df_train_ridge.iterrows():
    X.loc[idx, row['home_team']] = 1
    X.loc[idx, row['away_team']] = -1

# 目标变量 y: 净胜球 (Goal Differential)
# 你也可以尝试用 'home_xg - away_xg' 作为目标，或者两者的混合
y = df_train_ridge['home_goals'] - df_train_ridge['away_goals']

print(f"矩阵构建完成。形状: X={X.shape}, y={y.shape}")

============================================================
Cell 2 [code]
============================================================
# 定义参数网格
# alpha (正则化强度) 是我们需要优化的核心参数
param_grid = {
    'alpha': [0.1, 1.0, 5.0, 10.0, 20.0, 50.0, 100.0]
}

# 初始化岭回归模型
# fit_intercept=True 非常重要！截距 (Intercept) 代表了“主场优势 (HFA)”
ridge = Ridge(fit_intercept=True)

# 设置网格搜索 (使用 5折交叉验证)
grid_search = GridSearchCV(
    estimator=ridge,
    param_grid=param_grid,
    cv=5,                 # 5-Fold Cross Validation
    scoring='neg_mean_squared_error', # 目标是最小化均方误差
    verbose=1,
    n_jobs=-1             # 并行计算
)

# 开始训练
print("开始 Grid Search...")
grid_search.fit(X, y)

# 输出结果
best_alpha = grid_search.best_params_['alpha']
print(f"\n最佳 Alpha 值: {best_alpha}")
print(f"最佳 CV 分数 (Negative MSE): {grid_search.best_score_:.4f}")

============================================================
Cell 3 [code]
============================================================
# 使用最佳模型
best_model = grid_search.best_estimator_

# 1. 提取主场优势 (HFA)
# 岭回归的截距 = 当两队实力相等时，主队的预期净胜球
hfa_goals = best_model.intercept_
# 转换：通常 1 个净胜球 ≈ 25-30 Elo 分 (这是一个经验换算)
# 你可以直接用这个 hfa_goals * 30 作为你 Elo 模型里的 HFA 参数
hfa_elo_proxy = hfa_goals * 30 

print(f"--- 关键参数提取 ---")
print(f"主场优势 (HFA) - 净胜球: {hfa_goals:.4f}")
print(f"主场优势 (HFA) - Elo参考值: {hfa_elo_proxy:.2f}")

# 2. 提取球队实力排名
team_ratings = pd.DataFrame({
    'Team': teams,
    'Ridge_Rating': best_model.coef_
})

# 标准化：将 Rating 缩放到以 1500 为中心 (可选，为了方便和 Elo 比较)
# 这里我们简单地按系数排序
team_ratings = team_ratings.sort_values('Ridge_Rating', ascending=False).reset_index(drop=True)
team_ratings['Rank'] = team_ratings.index + 1

print("\n--- 球队实力排名 (Ridge Power Rankings Top 10) ---")
display(team_ratings.head(10))

# 可视化系数分布
plt.figure(figsize=(10, 6))
plt.bar(team_ratings['Team'][:10], team_ratings['Ridge_Rating'][:10])
plt.title('Top 10 Teams by Ridge Coefficient (Latent Strength)')
plt.xticks(rotation=45)
plt.ylabel('Strength Coefficient')
plt.show()

============================================================
Cell 4 [code]
============================================================
# 准备数据：预测“胜率” (Points Share)
# y = 主队获得的积分比例 (3分=1.0, 0分=0.0)
y_share = df_train_ridge['home_points'] / 3.0

# X = 比赛中的各项数据差值 (Diff)
X_stats = pd.DataFrame({
    'Goal_Diff': df_train_ridge['home_goals'] - df_train_ridge['away_goals'],
    'xG_Diff': df_train_ridge['home_xg'] - df_train_ridge['away_xg'],
    'Shot_Diff': df_train_ridge['home_shots'] - df_train_ridge['away_shots']
})

# 简单的线性回归或岭回归来看系数
weight_model = Ridge(alpha=1.0)
weight_model.fit(X_stats, y_share)

# 提取系数并归一化
coeffs = np.abs(weight_model.coef_)
total = np.sum(coeffs)
weights = coeffs / total

print("\n--- Elo 权重建议 (Based on Regression) ---")
print(f"Goal Diff Weight: {weights[0]:.2f}")
print(f"xG Diff Weight:   {weights[1]:.2f}")
print(f"Shot Diff Weight: {weights[2]:.2f}")
print("(你可以将这些权重用于 Elo 更新公式中的 S_actual)")

============================================================
Cell 5 [code]
============================================================
import numpy as np
import pandas as pd
from sklearn.metrics import log_loss
from tqdm import tqdm  # 进度条，如果没安装可以去掉

# --- 在 GridSearch.ipynb 中修正参数设置 ---

# 1. 获取 Ridge 回归的截距 (净胜球单位)
hfa_goals = best_model.intercept_ 
print(f"Ridge 算出的主场净胜球优势: {hfa_goals:.4f}")

# 2. 【关键修正】转换为 Elo 分数单位
# 1 Goal Diff ≈ 35 Elo Points (这是一个稳健的经验值，介于 30-40 之间)
HFA_ELO = hfa_goals * 35.0 
print(f"转换后的 Elo 主场优势参数 (HFA): {HFA_ELO:.2f}")

# 3. 【关键修正】强制统一权重 (与 Processing.ipynb 保持一致)
# 放弃 Ridge 算出的 0.83，因为它太依赖“结果”而非“预测”
WEIGHT_GOALS = 0.4
WEIGHT_XG = 0.6

print(f"使用的权重: Goals={WEIGHT_GOALS}, xG={WEIGHT_XG}")

# 修复 KeyError: 'dataset_type'
# 因为 df_games 里的数据全部来自 whl_2025.csv，所以它们都是训练集
df_games['dataset_type'] = 'train'

# 检查一下是否添加成功
print("Columns:", df_games.columns)

# --- 2. 定义蒙特卡洛 Elo 评估函数 ---
def evaluate_elo_k(df, k_factor, hfa_elo, n_simulations=10):
    """
    运行 n 次蒙特卡洛模拟，返回该 K + HFA 下的平均 Log Loss (越低越好)
    """
    total_log_loss = 0.0

    # 只需要训练集
    df_train = df[df['dataset_type'] == 'train'].copy()

    for _ in range(n_simulations):
        # 核心：打乱比赛顺序 (Monte Carlo)
        df_shuffled = df_train.sample(frac=1).reset_index(drop=True)

        # 初始化分数
        ratings = {team: 1500.0 for team in pd.concat([df_train['home_team'], df_train['away_team']]).unique()}

        preds = []
        actuals = []

        for _, row in df_shuffled.iterrows():
            home, away = row['home_team'], row['away_team']
            r_home = ratings.get(home, 1500.0)
            r_away = ratings.get(away, 1500.0)

            # 1. 计算胜率期望 (加入 HFA)
            prob_home_win = 1 / (1 + 10 ** ((r_away - (r_home + hfa_elo)) / 400))

            # 2. 记录预测用于评估 (Log Loss)
            # 实际结果：如果主队积分>1.5 (即胜或加时胜) 记为 1，否则 0
            win_label = 1 if row['home_points'] > 1.5 else 0
            preds.append(prob_home_win)
            actuals.append(win_label)

            # 3. 计算“混合表现分” (S_actual)
            # 归一化积分: 3分->1.0, 2分->0.67, 1分->0.33, 0分->0.0
            score_points = row['home_points'] / 3.0

            # xG 占比
            total_xg = row['home_xg'] + row['away_xg']
            score_xg = row['home_xg'] / total_xg if total_xg > 0 else 0.5

            # 混合得分 (你的核心逻辑)
            s_actual = (WEIGHT_GOALS * score_points) + (WEIGHT_XG * score_xg)

            # 4. 更新分数
            # 胜利边际乘数 (MoV Multiplier)
            mov_mult = np.log(abs(row['home_goals'] - row['away_goals']) + 1)

            delta = k_factor * mov_mult * (s_actual - prob_home_win)
            ratings[home] += delta
            ratings[away] -= delta

        # 计算单次模拟的 Log Loss
        # clip 避免极端概率导致数值不稳定
        preds = np.clip(preds, 1e-6, 1 - 1e-6)
        total_log_loss += log_loss(actuals, preds)

    return total_log_loss / n_simulations

# --- 3. 运行网格搜索 (K + HFA) ---
k_values = [4, 6, 8, 10, 12, 15, 20, 25, 30]

# 以 Ridge 推断的 HFA 为中心做搜索
hfa_grid = [max(0, round(HFA_ELO + delta, 2)) for delta in [-40, -20, -10, 0, 10, 20, 40]]
hfa_grid = sorted(list(set(hfa_grid)))

best_k = None
best_hfa = None
best_score = float('inf')

print("开始 Elo K-Factor + HFA 网格搜索...")
print(f"{'K-Factor':<10} | {'HFA':<8} | {'Log Loss':<10}")
print("-" * 34)

for hfa in hfa_grid:
    for k in k_values:
        # 每个 K 值跑 5 次模拟取平均 (你可以增加这个数字以获得更稳定的结果)
        score = evaluate_elo_k(df_games, k, hfa, n_simulations=5)
        print(f"{k:<10} | {hfa:<8} | {score:.5f}")

        if score < best_score:
            best_score = score
            best_k = k
            best_hfa = hfa

print("-" * 34)
print(f"最佳 K 值: {best_k}")
print(f"最佳 HFA 值: {best_hfa}")
print(f"最佳 Log Loss: {best_score:.5f}")

